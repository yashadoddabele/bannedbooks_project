{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d3378dd",
   "metadata": {},
   "source": [
    "### Import Data, Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8f9dcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "from collections import Counter\n",
    "from scipy import stats\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbb315be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Title</th>\n",
       "      <th>Type of Ban</th>\n",
       "      <th>Secondary Author(s)</th>\n",
       "      <th>Illustrator(s)</th>\n",
       "      <th>Translator(s)</th>\n",
       "      <th>State</th>\n",
       "      <th>District</th>\n",
       "      <th>Date of Challenge/Removal</th>\n",
       "      <th>Origin of Challenge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Àbíké-Íyímídé, Faridah</td>\n",
       "      <td>Ace of Spades</td>\n",
       "      <td>Banned in Libraries and Classrooms</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Florida</td>\n",
       "      <td>Indian River County School District</td>\n",
       "      <td>2021-11-01</td>\n",
       "      <td>Administrator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acevedo, Elizabeth</td>\n",
       "      <td>Clap When You Land</td>\n",
       "      <td>Banned in Classrooms</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>Central York School District</td>\n",
       "      <td>2021-08-31</td>\n",
       "      <td>Administrator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Acevedo, Elizabeth</td>\n",
       "      <td>The Poet X</td>\n",
       "      <td>Banned in Libraries</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Florida</td>\n",
       "      <td>Indian River County School District</td>\n",
       "      <td>2021-11-01</td>\n",
       "      <td>Administrator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Acevedo, Elizabeth</td>\n",
       "      <td>The Poet X</td>\n",
       "      <td>Banned in Libraries and Classrooms</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York</td>\n",
       "      <td>Marlboro Central School District</td>\n",
       "      <td>2022-02-01</td>\n",
       "      <td>Administrator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Acevedo, Elizabeth</td>\n",
       "      <td>The Poet X</td>\n",
       "      <td>Banned Pending Investigation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Fredericksburg Independent School District</td>\n",
       "      <td>2022-03-01</td>\n",
       "      <td>Administrator</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Author               Title  \\\n",
       "0  Àbíké-Íyímídé, Faridah       Ace of Spades   \n",
       "1      Acevedo, Elizabeth  Clap When You Land   \n",
       "2      Acevedo, Elizabeth          The Poet X   \n",
       "3      Acevedo, Elizabeth          The Poet X   \n",
       "4      Acevedo, Elizabeth          The Poet X   \n",
       "\n",
       "                          Type of Ban Secondary Author(s) Illustrator(s)  \\\n",
       "0  Banned in Libraries and Classrooms                 NaN            NaN   \n",
       "1                Banned in Classrooms                 NaN            NaN   \n",
       "2                 Banned in Libraries                 NaN            NaN   \n",
       "3  Banned in Libraries and Classrooms                 NaN            NaN   \n",
       "4        Banned Pending Investigation                 NaN            NaN   \n",
       "\n",
       "  Translator(s)         State                                    District  \\\n",
       "0           NaN       Florida         Indian River County School District   \n",
       "1           NaN  Pennsylvania                Central York School District   \n",
       "2           NaN       Florida         Indian River County School District   \n",
       "3           NaN      New York            Marlboro Central School District   \n",
       "4           NaN         Texas  Fredericksburg Independent School District   \n",
       "\n",
       "  Date of Challenge/Removal Origin of Challenge  \n",
       "0                2021-11-01       Administrator  \n",
       "1                2021-08-31       Administrator  \n",
       "2                2021-11-01       Administrator  \n",
       "3                2022-02-01       Administrator  \n",
       "4                2022-03-01       Administrator  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_books = pd.read_excel(r\"pen_america_books.xlsx\")\n",
    "df_books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8241ede",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'books_1.Best_Books_Ever.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/bv/l21h2fw964n_ngz6qg8w1zjr0000gn/T/ipykernel_54711/3761201199.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_other\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"books_1.Best_Books_Ever.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_other\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1214\u001b[0m             \u001b[0;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[1;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'books_1.Best_Books_Ever.csv'"
     ]
    }
   ],
   "source": [
    "df_other = pd.read_csv(\"books_1.Best_Books_Ever.csv\")\n",
    "df_other.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3737561b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_allbooks = pd.merge(df_books, df_other, left_on=\"Title\", right_on=\"title\")\n",
    "df_allbooks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d05b01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# number of banned books also in df_other\n",
    "print(df_allbooks.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553b8bfa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# list of column names in merged dataframe\n",
    "for col in df_allbooks.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efd405b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop redundant columns\n",
    "df_allbooks.drop(columns=['title', 'author'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f87de11",
   "metadata": {},
   "source": [
    "## Question 1:  Which books are banned most frequently, and why are they banned?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461d3a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PART 1: MERGED DATASET\n",
    "\n",
    "#How many books in the dataset\n",
    "print(len(df_allbooks['Title'].unique()))\n",
    "\n",
    "#Books banned in order of frequency\n",
    "title_bans = df_allbooks.groupby('Title').size().sort_values(ascending=False)\n",
    "#10 most frequently banned books that appear in both dataframes\n",
    "title_bans[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c294e444",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PART 2: PEN DATASET ONLY\n",
    "#How many books in the dataset\n",
    "print(len(df_books['Title'].unique()))\n",
    "\n",
    "#Books banned in order of frequency\n",
    "pen_bans = df_books.groupby('Title').size().sort_values(ascending=False)\n",
    "#10 most frequently banned books that appear in both dataframes\n",
    "df_pen_bans = (pen_bans[:10]).to_frame(\"Count\").reset_index()\n",
    "df_pen_bans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec30b57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For graphing purposes, because the titles are quite long, replacing them with indexes:\n",
    "df_graph_bans = df_pen_bans\n",
    "df_graph_bans[\"Title\"] = df_graph_bans.index\n",
    "\n",
    "#Graph regarding the top 10 banned\n",
    "sns.catplot(data=df_pen_bans, x=\"Title\", y=\"Count\", kind=\"bar\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083efa93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Compiling this information with book descriptions and genres\n",
    "title_df = title_bans.to_frame(name=\"count\")\n",
    "relevant_info = pd.DataFrame().assign(Title=df_allbooks['Title'], genres=df_allbooks['genres'], description=df_allbooks['description'])\n",
    "relevant_info.head()\n",
    "\n",
    "#Dataframe with description info\n",
    "why_banned_descriptions = pd.merge(relevant_info, title_df, on=\"Title\")\n",
    "\n",
    "#Dataframe with just genres and unique Title entries\n",
    "why_banned_genres = why_banned_descriptions.drop_duplicates(subset=\"Title\", keep=\"last\")\n",
    "why_banned_genres = why_banned_genres.sort_values(by=\"count\", ascending=False)\n",
    "why_banned_genres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8c031d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top 10 banned books analysis\n",
    "top_banned = why_banned_genres[:10]\n",
    "lst = []\n",
    "for genre in top_banned['genres']:\n",
    "    lst = genre.split(\"['\")\n",
    "\n",
    "print(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8d8730",
   "metadata": {},
   "source": [
    "### Question 1: Manual Research over Book Content\n",
    "\n",
    "#### All information has been pulled from their Wikipedia pages.\n",
    "1. Synopses over the top 6 banned books in the PEN Dataset:\n",
    "  - _Gender Queer: A Memoir_ - A memoir recounting Maia Kobabe, an American cartoonist/author, and er journey with gender identity. Includes themes of gender dysphoria, gender binary, and asexuality. \n",
    "  - _All Boys Aren't Blue_ - A semi-autobiographical recount of activist George M. Johnson's expierences growing up queer and black in the United States. Targets themes of sexual abuse, racism, homophobia, and includes themes of consent, agency, and gender identity.\n",
    "  - _Out_of_Darkness_ - A love story between two teenagers, one Mexican-American and the other African-America, in thr 1930s. Incorporates the historical New London School explosion and targets themes of racism, classism, and historical segregation.\n",
    "  - _The Bluest Eye_ - A story following an African-American girl growing up after the Great Depression, recounting her struggles of racism. Targets themes of racism, sexism, child abuse, and sexual abuse.\n",
    "  - _Lawn_Boy_ - a semi-autobiographical recounting the experiences of a Mexican American boy growing up in the United States and the hardships he has faced. Targets themes of racism and discrimination.\n",
    "  - _The_Hate_U_Give_ - Tells the story of a young black teen in America who witness her childhood friend shot and killed by the police and her journey in attempting to find him justice. Targets themes of police brutality, racism, and discrimination.\n",
    "  \n",
    "  \n",
    "2. An analysis over these themes:\n",
    "  - Most banned books include stories that target topics such as homophobia, racism, sexism, classism, and other social discriminations. Considering the data accumulated in Question 2, these themes often are presented as inappropriate in more conservative areas for children to read, despite their relevance in education. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a10415f",
   "metadata": {},
   "source": [
    "## Question 2: Have trends in book bans changed over time, and if so, how? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4483ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of challenges for each unique date\n",
    "date_counts = df_books.groupby('Date of Challenge/Removal').count()['Author']\n",
    "date_counts = date_counts.to_frame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76975d65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dataframe of the dates, for merging\n",
    "unique_dates = pd.DataFrame(df_books['Date of Challenge/Removal'].unique())\n",
    "unique_dates = unique_dates.rename(columns = {0 : \"Date\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f75a1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe with dates and counts in order to plot\n",
    "merge_dates = unique_dates.merge(date_counts, how='left', left_on = 'Date', right_on = 'Date of Challenge/Removal')\n",
    "merge_dates.fillna(0, inplace = True)\n",
    "\n",
    "merge_dates = merge_dates.sort_values(by = 'Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675d7f99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot number of bans for each unique date\n",
    "\n",
    "sns.catplot(data = merge_dates, kind = \"bar\", x = \"Date\", y = \"Author\", color = \"cornflowerblue\",  \n",
    "            aspect = 1.5)\n",
    "\n",
    "plt.xlabel(\"Date\")\n",
    "plt.xticks(rotation = 45)\n",
    "\n",
    "# fix labels on x axis to remove timestamp\n",
    "labels = [tick.get_text()[:10] for tick in plt.gca().get_xticklabels()]\n",
    "plt.gca().set_xticklabels(labels)\n",
    "\n",
    "plt.ylabel(\"Number of Book Challenges\")\n",
    "\n",
    "plt.title(\"Number of Book Challenges for Each Date\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baef5ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_date_state = df_books.groupby(['Date of Challenge/Removal', 'State']).size().reset_index(name='count')\n",
    "pivot_group = group_date_state.pivot(index='Date of Challenge/Removal', columns='State', values='count')\n",
    "pivot_group.plot(kind='bar', stacked=True)\n",
    "\n",
    "plt.title('Book Ban Counts, by Date and State')\n",
    "\n",
    "plt.xlabel('Date')\n",
    "labels = [tick.get_text()[:10] for tick in plt.gca().get_xticklabels()]\n",
    "plt.gca().set_xticklabels(labels)\n",
    "\n",
    "plt.ylabel('Number of Bans')\n",
    "plt.legend(title='State', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb3e0a6",
   "metadata": {},
   "source": [
    "## Question 3: How do trends in banned books vary by genre? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c690c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert string of genres to list\n",
    "import ast\n",
    "def convert_to_list(x):\n",
    "    return ast.literal_eval(x)\n",
    "df_allbooks['genres'] = df_allbooks['genres'].apply(convert_to_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f95a5d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# count occurrences of each genre\n",
    "genre_counts = Counter([genre for genres in df_allbooks['genres'] for genre in genres])\n",
    "df_genre_counts = pd.DataFrame.from_dict(genre_counts, orient='index', columns=['count'])\n",
    "df_genre_counts = df_genre_counts.sort_values(by='count', ascending=False)\n",
    "df_genre_counts = df_genre_counts.reset_index().rename(columns={'index': 'genre'})\n",
    "\n",
    "specific_df_genre_counts = df_genre_counts[(df_genre_counts[\"genre\"] != \"Fiction\") & (df_genre_counts[\"genre\"] != \"Young Adult\") & (df_genre_counts[\"genre\"] != \"Contemporary\") & (df_genre_counts[\"genre\"] != \"Realistic Fiction\") & (df_genre_counts[\"genre\"] != \"Teen\") & (df_genre_counts[\"genre\"] != \"Audiobook\") & (df_genre_counts[\"genre\"] != \"Queer\") & (df_genre_counts[\"genre\"] != \"Young Adult Contemporary\") & (df_genre_counts[\"genre\"] != \"Adult\") & (df_genre_counts[\"genre\"] != \"Novels\") & (df_genre_counts[\"genre\"] != \"Historical Fiction\") & (df_genre_counts[\"genre\"] != \"Classics\") & (df_genre_counts[\"genre\"] != \"Literature\") & (df_genre_counts[\"genre\"] != \"Nonfiction\") & (df_genre_counts[\"genre\"] != \"Historical\") & (df_genre_counts[\"genre\"] != \"Adult Fiction\")]\n",
    "specific_df_genre_counts.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01722544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot 10 most banned genres\n",
    "sns.catplot(data = df_genre_counts.head(10), x = 'genre', y = 'count', kind = 'bar', aspect = 2)\n",
    "plt.xticks(rotation = 45)\n",
    "plt.xlabel(\"Genre\")\n",
    "plt.ylabel(\"Number of Books Banned\")\n",
    "plt.title(\"Top 10 Most Banned Genres\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512adde5",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Question 4: How do trends in book banning vary by state? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7cd855",
   "metadata": {},
   "source": [
    "For this step of analysis, we will be using the original PEN America (`df_books`) data rather than the merged dataframe with extra information on the books (`df_allbooks`), since we are interested in number of bans per state.\n",
    "\n",
    "Our definition of regions is based on regions defined by the U.S. Census Bureau. State populations are also based on information from the U.S. Census Bureau. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4deaa6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# which states had most bans\n",
    "state_bans = df_books.groupby('State').count().sort_values(by = 'Author', ascending = False)\n",
    "most_bans = state_bans.head()['Author'].to_frame()\n",
    "most_bans = most_bans.rename(columns = {'Author': 'Number of Bans'})\n",
    "most_bans\n",
    "\n",
    "most_bans = most_bans.sort_values(by='Number of Bans', ascending=True)  # sort values in ascending order\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "ax.barh(most_bans.index, most_bans['Number of Bans'], color='red')\n",
    "ax.set_title('Number of Books Banned by State (Top 5)')\n",
    "ax.set_xlabel('Number of Bans')\n",
    "ax.set_ylabel('State')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f7833d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# which states had fewest bans\n",
    "fewest_bans = state_bans.tail(10)['Author'].to_frame()\n",
    "fewest_bans = fewest_bans.rename(columns = {'Author' : 'Number of Bans'})\n",
    "fewest_bans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a205afc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe with just northeast states\n",
    "northeast = ['Connecticut', 'Maine', 'Massachusetts', 'New Hampshire', 'Rhode Island', 'Vermont', 'New Jersey', 'New York', 'Pennsylvania']\n",
    "northeast_df = df_books[df_books['State'].isin(northeast)]\n",
    "\n",
    "# count number of bans per state\n",
    "northeast_df_counts = northeast_df.groupby('State').count()['Author']\n",
    "northeast_counts = northeast_df_counts.to_frame()\n",
    "northeast_counts = northeast_counts.rename(columns = {'Author' : \"Number of Bans\"})\n",
    "\n",
    "# calculate mean number of bans per state\n",
    "ne_mean = np.mean(northeast_counts['Number of Bans'])\n",
    "\n",
    "print('northeastern mean:', ne_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e78a088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe with just southern states\n",
    "south = ['Delaware', 'District of Columbia', 'Florida', 'Georgia', 'Maryland', 'North Carolina', 'South Carolina', 'Virginia', 'West Virginia', 'Alabama', 'Kentucky', 'Mississippi', 'Tennessee', 'Arkansas', 'Louisiana', 'Oklahoma', 'Texas']\n",
    "south_df = df_books[df_books['State'].isin(south)]\n",
    "\n",
    "# count number of bans per state\n",
    "south_df_counts = south_df.groupby('State').count()['Author']\n",
    "south_counts = south_df_counts.to_frame()\n",
    "south_counts = south_counts.rename(columns = {'Author' : \"Number of Bans\"})\n",
    "\n",
    "# calculate mean number of bans per state\n",
    "south_mean = np.mean(south_counts['Number of Bans'])\n",
    "\n",
    "print('southern mean:', south_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f3586a",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_means = pd.DataFrame({'Region': ['Northeastern States', 'Southern States'],\n",
    "                             'Mean Number of Bans': [ne_mean, south_mean]})\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "ax.bar(region_means['Region'], region_means['Mean Number of Bans'], color=['blue', 'red'])\n",
    "ax.set_title('Mean Number of Books Banned by State Region')\n",
    "ax.set_xlabel('Region')\n",
    "ax.set_ylabel('Mean Number of Bans')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14411c48",
   "metadata": {},
   "source": [
    "We want to compare the mean number of book bans for northeastern states and southern states. We found that while the mean number of book bans for northeastern states is 79.5, the mean number of book bans for southern states is 167.5. We know that the true mean of banned books for southern states and northern states are different (there is no point to do a hypothesis test), and this might give us some insight on how the number of banned books is realted to the political and social climate of states in the northeast (traditionally more liberal) and the political and social climate of states in the south (traditionally more conservative)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba0d057",
   "metadata": {},
   "source": [
    "## Question 5: Who initiates book challenges and why? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517bb005",
   "metadata": {},
   "source": [
    "In this portion, we will group the books by their \"origin of challenge\" (who first proposed a book be banned; either from school administration, a formal challenge made by a parent or local resident, or other) and assess the demographic information of each books in each category in order to determine whether there is some underlying reason behind why a certain group of people challenges a book. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e201995a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_allbooks = pd.merge(df_books, df_other, left_on=\"Title\", right_on=\"title\")\n",
    "df_allbooks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169c53b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the total number of bans by origin of challenge\n",
    "df_allbooks.groupby(\"Origin of Challenge\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83af6faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#information about books grouped by origin of challenge\n",
    "df_allbooks.groupby(\"Origin of Challenge\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86968bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##plot showing total number of bans by origin of challenge\n",
    "sns.displot(data=df_allbooks, x=\"Origin of Challenge\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43442d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "##plot displaying the distribution of the liked perecentage by origin of \n",
    "sns.catplot(data = df_allbooks, x = \"Origin of Challenge\", y = \"likedPercent\", kind = \"box\", color = \"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad1dbac",
   "metadata": {},
   "source": [
    "Now that we have established that there may be some difference in the liked percentage between the three orgins of challenge categories, we will conduct a hypothesis test to determine whether the difference in mean like percentange for administrator banned books and formal challenge banned books is statistically significant. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a71446a",
   "metadata": {},
   "source": [
    "$H_0: \\mu_{admin} = \\mu_{formal}$\n",
    "\n",
    "$H_A:\\mu_{admin} \\neq \\mu_{formal}$\n",
    "\n",
    "\n",
    "**Null hypothesis:** there is no evidence of a statistically significant difference in mean like percentange for administrator banned books and formal challenge banned books.\n",
    "\n",
    "\n",
    "**Alternative hypothesis:** there is evidence of a statistically significant difference in mean like percentange for administrator banned books and formal challenge banned books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc049865",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask1 = df_allbooks[\"Origin of Challenge\"] == \"Administrator\"\n",
    "mask2 = df_allbooks[\"Origin of Challenge\"] == \"Formal Challenge\"\n",
    "\n",
    "admin = df_allbooks[mask1][\"likedPercent\"].tolist()\n",
    "formal = df_allbooks[mask2][\"likedPercent\"].tolist()\n",
    "\n",
    "stats.ttest_ind(admin, formal, equal_var = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fc08fd",
   "metadata": {},
   "source": [
    "Our p-value is 0.269 which is much greater than our predetermined significance level of 0.05. Thus, we fail to reject the null hypothesis there is no evidence of a statistically significant difference in mean like percentange for administrator banned books and formal challenge banned books. We have insufficient evidence to suggest a statistically significant difference in mean like percentange for administrator banned books and formal challenge banned books."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
